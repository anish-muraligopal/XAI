{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXQ3x0D7JyAI"
      },
      "source": [
        "# Grad-CAM: How to visualize class activation maps to bring Interpretability to Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHcx6uu8Pvg"
      },
      "source": [
        "# Usual Imports for Deep Learning\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Display\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvJWfPgrJk1g"
      },
      "source": [
        "model_builder = keras.applications.xception.Xception\n",
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions\n",
        "\n",
        "\n",
        "# using pretrained weights on ImageNet\n",
        "model = model_builder(weights=\"imagenet\")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate the last convolutional layer\n",
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "classifier_layer_names = [\n",
        "    \"avg_pool\",\n",
        "    \"predictions\",\n",
        "]\n",
        "\n",
        "# The local path to our target image\n",
        "img_path = keras.utils.get_file(\n",
        "    \"rabbit.jpg\", \"https://i.imgur.com/vH1MxgA.png\"\n",
        ")\n",
        "\n",
        "# Visualize the image\n",
        "display(Image(img_path))"
      ],
      "metadata": {
        "id": "aANpMmpVgGz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKf8wg1cOcTt"
      },
      "source": [
        "## The Grad-CAM algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McUVIyGgJlGp"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3). We do this because this dimension is needed for most built-in functions\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer_name, classifier_layer_names, prediction_rank=1):\n",
        "\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        pred_index = tf.argsort(preds)[0][-prediction_rank]\n",
        "        top_class_channel = preds[:, pred_index]\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNlewqMbUlh6"
      },
      "source": [
        "## Let's use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSx4Fef2JlN-"
      },
      "source": [
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "preds = model.predict(img_array)\n",
        "print(\"Top 1 Prediction:\", decode_predictions(preds, top=1)[0])\n",
        "\n",
        "# In order to check the 2nd and 3rd predicted class, we also print the predictions with top=3\n",
        "print(\"Top 3 Predictions:\", decode_predictions(preds, top=3)[0])\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(\n",
        "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
        ")\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ohlPk_1VA24"
      },
      "source": [
        "## Create a superimposed visualization\n",
        "\n",
        "Finally, we are going to superimpose this heatmap to the input image in order to easily visualize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4fEP1tUuHw"
      },
      "source": [
        "# We load the original image\n",
        "img = keras.preprocessing.image.load_img(img_path)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "# We use jet colormap to colorize heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "# We use RGB values of the colormap\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "# We create an image with RGB colorized heatmap\n",
        "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose the heatmap on original image\n",
        "superimposed_img = jet_heatmap * 0.4 + img #0.4 good value\n",
        "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "# Save the superimposed image\n",
        "save_path = \"rabbit_cam.jpg\"\n",
        "superimposed_img.save(save_path)\n",
        "\n",
        "# Display Grad CAM\n",
        "display(Image(save_path))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}