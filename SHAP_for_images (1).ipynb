{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "78RBqbIPk2lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F17tK8G6fBYU"
      },
      "outputs": [],
      "source": [
        "# pip install shap tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "EITgRM-Pk5E-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0XOu9bCe1np"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "ogQvDIAsk8Dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gLCE74Ee4RP"
      },
      "outputs": [],
      "source": [
        "# load pre-trained model and data\n",
        "model = ResNet50(weights=\"imagenet\")\n",
        "X, y = shap.datasets.imagenet50()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "AlFVPkpQ6Yzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[20])"
      ],
      "metadata": {
        "id": "kyZ_VDii4P4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling the Images"
      ],
      "metadata": {
        "id": "M2n_SFeolC0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X[8] contains integer data that needs to be scaled to the range [0, 255]\n",
        "X = np.clip(X, 0, 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "s-S20DS7lFck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display some sample images"
      ],
      "metadata": {
        "id": "5NhI1ku8uKq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[2])"
      ],
      "metadata": {
        "id": "i_XNzeHHtyyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02K6gohQmMrz"
      },
      "outputs": [],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageNet class names"
      ],
      "metadata": {
        "id": "bTS8AasllHiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6De5cBNe5c7"
      },
      "outputs": [],
      "source": [
        "# getting ImageNet 1000 class names\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "with open(shap.datasets.cache(url)) as file:\n",
        "    class_names = [v[1] for v in json.load(file).values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fey_IuKNfXQT"
      },
      "outputs": [],
      "source": [
        "print(\"Number of ImageNet classes:\", len(class_names))\n",
        "print(\"Class names:\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define SHAP explainer"
      ],
      "metadata": {
        "id": "7p0SlYHAlTQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[17])"
      ],
      "metadata": {
        "id": "s-2TG7Ul6J86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM8DQBIRe7BS"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    tmp = x.copy()\n",
        "    preprocess_input(tmp)\n",
        "    return model(tmp)\n",
        "\n",
        "# define a masker that is used to mask out partitions of the input image.\n",
        "masker = shap.maskers.Image(\"inpaint_telea\", X[0].shape)\n",
        "\n",
        "# create an explainer with model and image masker\n",
        "explainer = shap.Explainer(f, masker, output_names=class_names)\n",
        "\n",
        "# here we explain two images using 100 evaluations of the underlying model to estimate the SHAP values\n",
        "shap_values = explainer(\n",
        "    X[1:3], max_evals=100, batch_size=50, outputs=shap.Explanation.argsort.flip[:4]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot SHAP values on the image"
      ],
      "metadata": {
        "id": "20lPlNw_lWPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuQxlbIte8pM"
      },
      "outputs": [],
      "source": [
        "# output with shap values\n",
        "shap.image_plot(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run SHAP for 500 evaluations"
      ],
      "metadata": {
        "id": "sW6p7qZplcDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OYhi-L9e-XA"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    tmp = x.copy()\n",
        "    preprocess_input(tmp)\n",
        "    return model(tmp)\n",
        "\n",
        "# define a masker that is used to mask out partitions of the input image.\n",
        "masker_blur = shap.maskers.Image(\"blur(128,128)\", X[0].shape)\n",
        "\n",
        "# create an explainer with model and image masker\n",
        "explainer_blur = shap.Explainer(f, masker_blur, output_names=class_names)\n",
        "\n",
        "# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\n",
        "shap_values_fine = explainer_blur(\n",
        "    X[1:3], max_evals=500, batch_size=50, outputs=shap.Explanation.argsort.flip[:4]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot SHAP output"
      ],
      "metadata": {
        "id": "kfK71QQtleb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTcNBS5ze_5Q"
      },
      "outputs": [],
      "source": [
        "# output with shap values\n",
        "shap.image_plot(shap_values_fine)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}